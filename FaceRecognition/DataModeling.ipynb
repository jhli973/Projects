{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from LoadSplitData import Process\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape (24076, 80, 80, 3), label shape (24076,), ratio of authorized data 0.4503655092208008\n",
      "X_train shape: (12639, 80, 80, 3)\n",
      "12639 train samples\n",
      "5418 valid samples\n",
      "6019 test samples\n"
     ]
    }
   ],
   "source": [
    "data = Process()\n",
    "data.split_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from BuildModel import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 80, 80, 32)    896         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 80, 80, 32)    9248        convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 40, 40, 32)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 40, 40, 32)    0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 40, 40, 64)    18496       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 40, 40, 64)    36928       convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 20, 20, 64)    0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 20, 20, 64)    0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 20, 20, 96)    55392       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 20, 20, 96)    83040       convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 10, 10, 96)    0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 10, 10, 96)    0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 9600)          0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 960)           9216960     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 960)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 960)           0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 2)             1922        dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 2)             0           dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 98s - loss: 0.4368 - acc: 0.8016 - val_loss: 0.3668 - val_acc: 0.8415\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.3170 - acc: 0.8650 - val_loss: 0.2952 - val_acc: 0.8846\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.2278 - acc: 0.9079 - val_loss: 0.2302 - val_acc: 0.9079\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.1591 - acc: 0.9375 - val_loss: 0.1087 - val_acc: 0.9611\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.1216 - acc: 0.9549 - val_loss: 0.0849 - val_acc: 0.9692\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.1001 - acc: 0.9626 - val_loss: 0.0621 - val_acc: 0.9797\n",
      "Epoch 7/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0856 - acc: 0.9665 - val_loss: 0.0653 - val_acc: 0.9773\n",
      "Model Saved.\n",
      "Optimizer: sgd, batch_size: 40, test accuracy: 97.74048739957897\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_7 (Convolution2D)  (None, 80, 80, 32)    896         convolution2d_input_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 80, 80, 32)    9248        convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 40, 40, 32)    0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 40, 40, 32)    0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 40, 40, 64)    18496       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 20, 20, 64)    0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 20, 20, 64)    0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 20, 20, 96)    55392       dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 10, 10, 96)    0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 10, 10, 96)    0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 9600)          0           dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 960)           9216960     flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 960)           0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 960)           0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 2)             1922        dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 2)             0           dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.4460 - acc: 0.7951 - val_loss: 0.3638 - val_acc: 0.8522\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.3348 - acc: 0.8555 - val_loss: 0.3201 - val_acc: 0.8734\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.2721 - acc: 0.8889 - val_loss: 0.3113 - val_acc: 0.8708\n",
      "Model Saved.\n",
      "Optimizer: sgd, batch_size: 50, test accuracy: 86.67552632179584\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_13 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_7 (MaxPooling2D)    (None, 40, 40, 32)    0           convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 40, 40, 32)    0           maxpooling2d_7[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 40, 40, 64)    18496       dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_16 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_8 (MaxPooling2D)    (None, 20, 20, 64)    0           convolution2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_8[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_17 (Convolution2D) (None, 20, 20, 96)    55392       dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_18 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_9 (MaxPooling2D)    (None, 10, 10, 96)    0           convolution2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_9[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 9600)          0           dropout_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 960)           9216960     flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 960)           0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 960)           0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 2)             1922        dropout_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 2)             0           dense_6[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 92s - loss: 0.4724 - acc: 0.7711 - val_loss: 0.3877 - val_acc: 0.8328\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 89s - loss: 0.3515 - acc: 0.8480 - val_loss: 0.3192 - val_acc: 0.8649\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 90s - loss: 0.3058 - acc: 0.8722 - val_loss: 0.3043 - val_acc: 0.8706\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 90s - loss: 0.2524 - acc: 0.8950 - val_loss: 0.2070 - val_acc: 0.9243\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 89s - loss: 0.1970 - acc: 0.9211 - val_loss: 0.1507 - val_acc: 0.9489\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 89s - loss: 0.1537 - acc: 0.9388 - val_loss: 0.1413 - val_acc: 0.9480\n",
      "Model Saved.\n",
      "Optimizer: sgd, batch_size: 60, test accuracy: 94.65027886840033\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_19 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_20 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_10 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_10[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_21 (Convolution2D) (None, 40, 40, 64)    18496       dropout_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_22 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_11 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_11[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_23 (Convolution2D) (None, 20, 20, 96)    55392       dropout_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_24 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_12 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_12[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 9600)          0           dropout_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 960)           9216960     flatten_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 960)           0           dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)             (None, 960)           0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 2)             1922        dropout_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 2)             0           dense_8[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.5451 - acc: 0.7262 - val_loss: 0.3910 - val_acc: 0.8376\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 88s - loss: 0.3643 - acc: 0.8428 - val_loss: 0.3390 - val_acc: 0.8605\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 88s - loss: 0.3292 - acc: 0.8590 - val_loss: 0.3063 - val_acc: 0.8677\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 89s - loss: 0.2808 - acc: 0.8809 - val_loss: 0.2358 - val_acc: 0.9101\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 88s - loss: 0.2328 - acc: 0.9063 - val_loss: 0.1808 - val_acc: 0.9306\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 88s - loss: 0.1888 - acc: 0.9273 - val_loss: 0.1354 - val_acc: 0.9539\n",
      "Epoch 7/30\n",
      "12639/12639 [==============================] - 88s - loss: 0.1494 - acc: 0.9444 - val_loss: 0.1517 - val_acc: 0.9400\n",
      "Model Saved.\n",
      "Optimizer: sgd, batch_size: 70, test accuracy: 93.7863444664051\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_25 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_26 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_25[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_13 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_13[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_27 (Convolution2D) (None, 40, 40, 64)    18496       dropout_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_28 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_27[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_14 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_28[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_14[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_29 (Convolution2D) (None, 20, 20, 96)    55392       dropout_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_30 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_29[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_15 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_30[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_15[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 9600)          0           dropout_19[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 960)           9216960     flatten_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 960)           0           dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)             (None, 960)           0           activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 2)             1922        dropout_20[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 2)             0           dense_10[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.4909 - acc: 0.7621 - val_loss: 0.3865 - val_acc: 0.8409\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 87s - loss: 0.3654 - acc: 0.8411 - val_loss: 0.3533 - val_acc: 0.8501\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 87s - loss: 0.3271 - acc: 0.8584 - val_loss: 0.3322 - val_acc: 0.8568\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 87s - loss: 0.2952 - acc: 0.8755 - val_loss: 0.2614 - val_acc: 0.9013\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 87s - loss: 0.2505 - acc: 0.8966 - val_loss: 0.2435 - val_acc: 0.9068\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 87s - loss: 0.2100 - acc: 0.9142 - val_loss: 0.2446 - val_acc: 0.8994\n",
      "Model Saved.\n",
      "Optimizer: sgd, batch_size: 80, test accuracy: 90.09802515254422\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_31 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_32 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_31[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_16 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_32[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_16[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_33 (Convolution2D) (None, 40, 40, 64)    18496       dropout_21[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_34 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_33[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_17 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_34[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_17[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_35 (Convolution2D) (None, 20, 20, 96)    55392       dropout_22[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_36 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_35[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_18 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_36[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_18[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 9600)          0           dropout_23[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 960)           9216960     flatten_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 960)           0           dense_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)             (None, 960)           0           activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 2)             1922        dropout_24[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 2)             0           dense_12[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 90s - loss: 0.5915 - acc: 0.6786 - val_loss: 0.4100 - val_acc: 0.8291\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 87s - loss: 0.3954 - acc: 0.8261 - val_loss: 0.3780 - val_acc: 0.8409\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 87s - loss: 0.3502 - acc: 0.8472 - val_loss: 0.3663 - val_acc: 0.8403\n",
      "Model Saved.\n",
      "Optimizer: sgd, batch_size: 90, test accuracy: 83.7680718137846\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_37 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_38 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_37[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_19 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_38[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_19[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_39 (Convolution2D) (None, 40, 40, 64)    18496       dropout_25[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_40 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_39[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_20 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_40[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_20[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_41 (Convolution2D) (None, 20, 20, 96)    55392       dropout_26[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_42 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_41[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_21 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_42[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_21[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)              (None, 9600)          0           dropout_27[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 960)           9216960     flatten_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 960)           0           dense_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)             (None, 960)           0           activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 2)             1922        dropout_28[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 2)             0           dense_14[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 105s - loss: 0.1942 - acc: 0.9172 - val_loss: 0.0493 - val_acc: 0.9817\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 104s - loss: 0.0733 - acc: 0.9744 - val_loss: 0.0455 - val_acc: 0.9856\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 105s - loss: 0.0515 - acc: 0.9812 - val_loss: 0.0266 - val_acc: 0.9900\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 104s - loss: 0.0370 - acc: 0.9870 - val_loss: 0.0211 - val_acc: 0.9932\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 104s - loss: 0.0333 - acc: 0.9889 - val_loss: 0.0195 - val_acc: 0.9937\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 104s - loss: 0.0320 - acc: 0.9894 - val_loss: 0.0178 - val_acc: 0.9945\n",
      "Epoch 7/30\n",
      "12639/12639 [==============================] - 104s - loss: 0.0243 - acc: 0.9920 - val_loss: 0.0157 - val_acc: 0.9956\n",
      "Epoch 8/30\n",
      "12639/12639 [==============================] - 104s - loss: 0.0250 - acc: 0.9910 - val_loss: 0.0098 - val_acc: 0.9965\n",
      "Epoch 9/30\n",
      "12639/12639 [==============================] - 104s - loss: 0.0204 - acc: 0.9930 - val_loss: 0.0093 - val_acc: 0.9967\n",
      "Epoch 10/30\n",
      "12639/12639 [==============================] - 104s - loss: 0.0206 - acc: 0.9938 - val_loss: 0.0131 - val_acc: 0.9959\n",
      "Model Saved.\n",
      "Optimizer: adam, batch_size: 40, test accuracy: 99.61787629590951\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_43 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_44 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_43[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_22 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_44[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_22[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_45 (Convolution2D) (None, 40, 40, 64)    18496       dropout_29[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_46 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_45[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_23 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_46[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_23[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_47 (Convolution2D) (None, 20, 20, 96)    55392       dropout_30[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_48 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_47[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_24 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_48[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_24[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)              (None, 9600)          0           dropout_31[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (None, 960)           9216960     flatten_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 960)           0           dense_15[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)             (None, 960)           0           activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_16 (Dense)                 (None, 2)             1922        dropout_32[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 2)             0           dense_16[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 101s - loss: 0.1976 - acc: 0.9130 - val_loss: 0.0772 - val_acc: 0.9719\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 100s - loss: 0.0702 - acc: 0.9737 - val_loss: 0.0265 - val_acc: 0.9908\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 100s - loss: 0.0499 - acc: 0.9835 - val_loss: 0.0236 - val_acc: 0.9921\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 100s - loss: 0.0396 - acc: 0.9869 - val_loss: 0.0157 - val_acc: 0.9945\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 100s - loss: 0.0306 - acc: 0.9896 - val_loss: 0.0191 - val_acc: 0.9935\n",
      "Model Saved.\n",
      "Optimizer: adam, batch_size: 50, test accuracy: 99.28559560200605\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_49 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_50 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_49[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_25 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_50[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_25[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_51 (Convolution2D) (None, 40, 40, 64)    18496       dropout_33[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_52 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_51[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_26 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_52[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_26[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_53 (Convolution2D) (None, 20, 20, 96)    55392       dropout_34[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_54 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_53[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_27 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_54[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_27[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)              (None, 9600)          0           dropout_35[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_17 (Dense)                 (None, 960)           9216960     flatten_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 960)           0           dense_17[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)             (None, 960)           0           activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_18 (Dense)                 (None, 2)             1922        dropout_36[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 2)             0           dense_18[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 98s - loss: 0.2251 - acc: 0.8995 - val_loss: 0.0601 - val_acc: 0.9784\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 97s - loss: 0.0754 - acc: 0.9743 - val_loss: 0.0518 - val_acc: 0.9815\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 97s - loss: 0.0511 - acc: 0.9824 - val_loss: 0.0255 - val_acc: 0.9895\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 97s - loss: 0.0371 - acc: 0.9874 - val_loss: 0.0265 - val_acc: 0.9893\n",
      "Model Saved.\n",
      "Optimizer: adam, batch_size: 60, test accuracy: 98.87024619528218\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_55 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_56 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_55[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_28 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_56[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_28[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_57 (Convolution2D) (None, 40, 40, 64)    18496       dropout_37[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_58 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_57[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_29 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_58[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_29[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_59 (Convolution2D) (None, 20, 20, 96)    55392       dropout_38[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_60 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_59[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_30 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_60[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_30[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)             (None, 9600)          0           dropout_39[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_19 (Dense)                 (None, 960)           9216960     flatten_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 960)           0           dense_19[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)             (None, 960)           0           activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_20 (Dense)                 (None, 2)             1922        dropout_40[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 2)             0           dense_20[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 96s - loss: 0.2595 - acc: 0.8844 - val_loss: 0.1191 - val_acc: 0.9579\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 95s - loss: 0.0814 - acc: 0.9718 - val_loss: 0.0401 - val_acc: 0.9845\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 95s - loss: 0.0546 - acc: 0.9810 - val_loss: 0.0237 - val_acc: 0.9915\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 95s - loss: 0.0407 - acc: 0.9858 - val_loss: 0.0232 - val_acc: 0.9937\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 95s - loss: 0.0323 - acc: 0.9890 - val_loss: 0.0109 - val_acc: 0.9969\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 95s - loss: 0.0270 - acc: 0.9905 - val_loss: 0.0125 - val_acc: 0.9950\n",
      "Model Saved.\n",
      "Optimizer: adam, batch_size: 70, test accuracy: 99.7009472328873\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_61 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_62 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_61[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_31 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_62[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_31[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_63 (Convolution2D) (None, 40, 40, 64)    18496       dropout_41[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_64 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_63[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_32 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_64[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_32[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_65 (Convolution2D) (None, 20, 20, 96)    55392       dropout_42[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_66 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_65[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_33 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_66[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_33[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)             (None, 9600)          0           dropout_43[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_21 (Dense)                 (None, 960)           9216960     flatten_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 960)           0           dense_21[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)             (None, 960)           0           activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_22 (Dense)                 (None, 2)             1922        dropout_44[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 2)             0           dense_22[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 94s - loss: 0.2403 - acc: 0.8904 - val_loss: 0.0821 - val_acc: 0.9697\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0781 - acc: 0.9730 - val_loss: 0.0435 - val_acc: 0.9867\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0523 - acc: 0.9820 - val_loss: 0.0255 - val_acc: 0.9926\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0369 - acc: 0.9870 - val_loss: 0.0160 - val_acc: 0.9946\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0351 - acc: 0.9878 - val_loss: 0.0184 - val_acc: 0.9934\n",
      "Model Saved.\n",
      "Optimizer: adam, batch_size: 80, test accuracy: 99.41850750326299\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_67 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_68 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_67[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_34 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_68[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_34[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_69 (Convolution2D) (None, 40, 40, 64)    18496       dropout_45[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_70 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_69[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_35 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_70[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_35[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_71 (Convolution2D) (None, 20, 20, 96)    55392       dropout_46[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_72 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_71[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_36 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_72[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_36[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)             (None, 9600)          0           dropout_47[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_23 (Dense)                 (None, 960)           9216960     flatten_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 960)           0           dense_23[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)             (None, 960)           0           activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_24 (Dense)                 (None, 2)             1922        dropout_48[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 2)             0           dense_24[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.2625 - acc: 0.8783 - val_loss: 0.0701 - val_acc: 0.9760\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 92s - loss: 0.0802 - acc: 0.9718 - val_loss: 0.0497 - val_acc: 0.9801\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 92s - loss: 0.0511 - acc: 0.9828 - val_loss: 0.0213 - val_acc: 0.9935\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 92s - loss: 0.0392 - acc: 0.9866 - val_loss: 0.0258 - val_acc: 0.9902\n",
      "Model Saved.\n",
      "Optimizer: adam, batch_size: 90, test accuracy: 98.95331652027009\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_73 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_74 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_73[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_37 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_74[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_37[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_75 (Convolution2D) (None, 40, 40, 64)    18496       dropout_49[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_76 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_75[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_38 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_76[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_38[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_77 (Convolution2D) (None, 20, 20, 96)    55392       dropout_50[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_78 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_77[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_39 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_78[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_39[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)             (None, 9600)          0           dropout_51[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_25 (Dense)                 (None, 960)           9216960     flatten_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 960)           0           dense_25[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)             (None, 960)           0           activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_26 (Dense)                 (None, 2)             1922        dropout_52[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 2)             0           dense_26[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 101s - loss: 0.1938 - acc: 0.9224 - val_loss: 0.0916 - val_acc: 0.9625\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 101s - loss: 0.0700 - acc: 0.9757 - val_loss: 0.0350 - val_acc: 0.9871\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 101s - loss: 0.0485 - acc: 0.9835 - val_loss: 0.0250 - val_acc: 0.9904\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 101s - loss: 0.0342 - acc: 0.9877 - val_loss: 0.0175 - val_acc: 0.9945\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 101s - loss: 0.0244 - acc: 0.9915 - val_loss: 0.0125 - val_acc: 0.9958\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 101s - loss: 0.0260 - acc: 0.9921 - val_loss: 0.0145 - val_acc: 0.9954\n",
      "Model Saved.\n",
      "Optimizer: adamax, batch_size: 40, test accuracy: 99.6178763355205\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_79 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_80 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_79[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_40 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_80[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_40[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_81 (Convolution2D) (None, 40, 40, 64)    18496       dropout_53[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_82 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_81[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_41 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_82[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_41[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_83 (Convolution2D) (None, 20, 20, 96)    55392       dropout_54[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_84 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_83[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_42 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_84[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_42[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)             (None, 9600)          0           dropout_55[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_27 (Dense)                 (None, 960)           9216960     flatten_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 960)           0           dense_27[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)             (None, 960)           0           activation_27[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_28 (Dense)                 (None, 2)             1922        dropout_56[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 2)             0           dense_28[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 98s - loss: 0.2313 - acc: 0.8931 - val_loss: 0.0888 - val_acc: 0.9694\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 97s - loss: 0.0775 - acc: 0.9740 - val_loss: 0.0564 - val_acc: 0.9788\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 97s - loss: 0.0616 - acc: 0.9774 - val_loss: 0.0317 - val_acc: 0.9884\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 97s - loss: 0.0452 - acc: 0.9838 - val_loss: 0.0254 - val_acc: 0.9910\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 97s - loss: 0.0347 - acc: 0.9880 - val_loss: 0.0151 - val_acc: 0.9943\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 97s - loss: 0.0274 - acc: 0.9906 - val_loss: 0.0185 - val_acc: 0.9922\n",
      "Model Saved.\n",
      "Optimizer: adamax, batch_size: 50, test accuracy: 99.2689815623595\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_85 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_15[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_86 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_85[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_43 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_86[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_43[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_87 (Convolution2D) (None, 40, 40, 64)    18496       dropout_57[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_88 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_87[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_44 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_88[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_44[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_89 (Convolution2D) (None, 20, 20, 96)    55392       dropout_58[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_90 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_89[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_45 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_90[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_45[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)             (None, 9600)          0           dropout_59[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_29 (Dense)                 (None, 960)           9216960     flatten_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, 960)           0           dense_29[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)             (None, 960)           0           activation_29[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_30 (Dense)                 (None, 2)             1922        dropout_60[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, 2)             0           dense_30[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 95s - loss: 0.2616 - acc: 0.8833 - val_loss: 0.0566 - val_acc: 0.9810\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 94s - loss: 0.0800 - acc: 0.9725 - val_loss: 0.0436 - val_acc: 0.9847\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 94s - loss: 0.0537 - acc: 0.9814 - val_loss: 0.0390 - val_acc: 0.9862\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 94s - loss: 0.0397 - acc: 0.9865 - val_loss: 0.0187 - val_acc: 0.9934\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 94s - loss: 0.0351 - acc: 0.9894 - val_loss: 0.0182 - val_acc: 0.9939\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 94s - loss: 0.0302 - acc: 0.9901 - val_loss: 0.0297 - val_acc: 0.9891\n",
      "Model Saved.\n",
      "Optimizer: adamax, batch_size: 60, test accuracy: 99.01977278976707\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_91 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_16[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_92 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_91[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_46 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_92[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_46[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_93 (Convolution2D) (None, 40, 40, 64)    18496       dropout_61[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_94 (Convolution2D) (None, 40, 40, 64)    36928       convolution2d_93[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_47 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_94[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_47[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_95 (Convolution2D) (None, 20, 20, 96)    55392       dropout_62[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_96 (Convolution2D) (None, 20, 20, 96)    83040       convolution2d_95[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_48 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_96[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_48[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)             (None, 9600)          0           dropout_63[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_31 (Dense)                 (None, 960)           9216960     flatten_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, 960)           0           dense_31[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)             (None, 960)           0           activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_32 (Dense)                 (None, 2)             1922        dropout_64[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, 2)             0           dense_32[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 94s - loss: 0.2620 - acc: 0.8842 - val_loss: 0.0715 - val_acc: 0.9743\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0810 - acc: 0.9703 - val_loss: 0.0450 - val_acc: 0.9847\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0538 - acc: 0.9809 - val_loss: 0.0319 - val_acc: 0.9873\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0390 - acc: 0.9873 - val_loss: 0.0209 - val_acc: 0.9921\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0341 - acc: 0.9894 - val_loss: 0.0164 - val_acc: 0.9946\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0306 - acc: 0.9891 - val_loss: 0.0137 - val_acc: 0.9948\n",
      "Epoch 7/30\n",
      "12639/12639 [==============================] - 93s - loss: 0.0267 - acc: 0.9919 - val_loss: 0.0137 - val_acc: 0.9941\n",
      "Model Saved.\n",
      "Optimizer: adamax, batch_size: 70, test accuracy: 99.48496466004624\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_97 (Convolution2D) (None, 80, 80, 32)    896         convolution2d_input_17[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_98 (Convolution2D) (None, 80, 80, 32)    9248        convolution2d_97[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_49 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_98[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_49[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_99 (Convolution2D) (None, 40, 40, 64)    18496       dropout_65[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_100 (Convolution2D (None, 40, 40, 64)    36928       convolution2d_99[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_50 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_100[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_50[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_101 (Convolution2D (None, 20, 20, 96)    55392       dropout_66[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_102 (Convolution2D (None, 20, 20, 96)    83040       convolution2d_101[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_51 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_102[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_51[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)             (None, 9600)          0           dropout_67[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_33 (Dense)                 (None, 960)           9216960     flatten_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, 960)           0           dense_33[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)             (None, 960)           0           activation_33[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_34 (Dense)                 (None, 2)             1922        dropout_68[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, 2)             0           dense_34[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 92s - loss: 0.2644 - acc: 0.8754 - val_loss: 0.0823 - val_acc: 0.9721\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.0809 - acc: 0.9713 - val_loss: 0.0498 - val_acc: 0.9817\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.0621 - acc: 0.9806 - val_loss: 0.0339 - val_acc: 0.9889\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.0473 - acc: 0.9834 - val_loss: 0.0275 - val_acc: 0.9898\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.0397 - acc: 0.9868 - val_loss: 0.0314 - val_acc: 0.9902\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.0318 - acc: 0.9896 - val_loss: 0.0146 - val_acc: 0.9956\n",
      "Epoch 7/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.0310 - acc: 0.9903 - val_loss: 0.0132 - val_acc: 0.9963\n",
      "Epoch 8/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.0231 - acc: 0.9916 - val_loss: 0.0121 - val_acc: 0.9952\n",
      "Model Saved.\n",
      "Optimizer: adamax, batch_size: 80, test accuracy: 99.3520512654548\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_103 (Convolution2D (None, 80, 80, 32)    896         convolution2d_input_18[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_104 (Convolution2D (None, 80, 80, 32)    9248        convolution2d_103[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_52 (MaxPooling2D)   (None, 40, 40, 32)    0           convolution2d_104[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)             (None, 40, 40, 32)    0           maxpooling2d_52[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_105 (Convolution2D (None, 40, 40, 64)    18496       dropout_69[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_106 (Convolution2D (None, 40, 40, 64)    36928       convolution2d_105[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_53 (MaxPooling2D)   (None, 20, 20, 64)    0           convolution2d_106[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)             (None, 20, 20, 64)    0           maxpooling2d_53[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_107 (Convolution2D (None, 20, 20, 96)    55392       dropout_70[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_108 (Convolution2D (None, 20, 20, 96)    83040       convolution2d_107[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_54 (MaxPooling2D)   (None, 10, 10, 96)    0           convolution2d_108[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)             (None, 10, 10, 96)    0           maxpooling2d_54[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)             (None, 9600)          0           dropout_71[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_35 (Dense)                 (None, 960)           9216960     flatten_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, 960)           0           dense_35[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)             (None, 960)           0           activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_36 (Dense)                 (None, 2)             1922        dropout_72[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, 2)             0           dense_36[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,422,882\n",
      "Trainable params: 9,422,882\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/30\n",
      "12639/12639 [==============================] - 91s - loss: 0.2979 - acc: 0.8629 - val_loss: 0.0677 - val_acc: 0.9790\n",
      "Epoch 2/30\n",
      "12639/12639 [==============================] - 90s - loss: 0.0916 - acc: 0.9684 - val_loss: 0.0511 - val_acc: 0.9832\n",
      "Epoch 3/30\n",
      "12639/12639 [==============================] - 90s - loss: 0.0609 - acc: 0.9797 - val_loss: 0.0359 - val_acc: 0.9874\n",
      "Epoch 4/30\n",
      "12639/12639 [==============================] - 90s - loss: 0.0525 - acc: 0.9828 - val_loss: 0.0278 - val_acc: 0.9897\n",
      "Epoch 5/30\n",
      "12639/12639 [==============================] - 90s - loss: 0.0481 - acc: 0.9831 - val_loss: 0.0254 - val_acc: 0.9908\n",
      "Epoch 6/30\n",
      "12639/12639 [==============================] - 90s - loss: 0.0365 - acc: 0.9885 - val_loss: 0.0281 - val_acc: 0.9900\n",
      "Model Saved.\n",
      "Optimizer: adamax, batch_size: 90, test accuracy: 98.72072094559056\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = r'C:\\Users\\dbsnail\\ImageProject\\models\\ml' #_sgd.h5'\n",
    "optimizers = ['sgd', 'adam', 'adamax']\n",
    "batch_sizes = [40, 50, 60, 70, 80, 90]\n",
    "\n",
    "model_dict = {}\n",
    "for optimizer in optimizers:\n",
    "    for batch_size in batch_sizes:\n",
    "    \n",
    "        file_path = FILE_PATH + '_' + str(batch_size) + '_' + optimizer + '.h5'\n",
    "        model = Model(batch_size)\n",
    "        model.build_model(data)\n",
    "        model.train(data,optimizer)\n",
    "        model.save(file_path)\n",
    "        acc = model.evaluate(data)\n",
    "        print(\"Optimizer: {}, batch_size: {}, test accuracy: {}\".format(optimizer, batch_size, acc))\n",
    "        if optimizer in model_dict.keys():\n",
    "            model_dict[optimizer].append((batch_size, acc))\n",
    "        else:\n",
    "            model_dict[optimizer] = [(batch_size, acc)]           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adam</th>\n",
       "      <th>adamax</th>\n",
       "      <th>sgd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(40, 99.6178762959)</td>\n",
       "      <td>(40, 99.6178763355)</td>\n",
       "      <td>(40, 97.7404873996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(50, 99.285595602)</td>\n",
       "      <td>(50, 99.2689815624)</td>\n",
       "      <td>(50, 86.6755263218)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(60, 98.8702461953)</td>\n",
       "      <td>(60, 99.0197727898)</td>\n",
       "      <td>(60, 94.6502788684)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(70, 99.7009472329)</td>\n",
       "      <td>(70, 99.48496466)</td>\n",
       "      <td>(70, 93.7863444664)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(80, 99.4185075033)</td>\n",
       "      <td>(80, 99.3520512655)</td>\n",
       "      <td>(80, 90.0980251525)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(90, 98.9533165203)</td>\n",
       "      <td>(90, 98.7207209456)</td>\n",
       "      <td>(90, 83.7680718138)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  adam               adamax                  sgd\n",
       "0  (40, 99.6178762959)  (40, 99.6178763355)  (40, 97.7404873996)\n",
       "1   (50, 99.285595602)  (50, 99.2689815624)  (50, 86.6755263218)\n",
       "2  (60, 98.8702461953)  (60, 99.0197727898)  (60, 94.6502788684)\n",
       "3  (70, 99.7009472329)    (70, 99.48496466)  (70, 93.7863444664)\n",
       "4  (80, 99.4185075033)  (80, 99.3520512655)  (80, 90.0980251525)\n",
       "5  (90, 98.9533165203)  (90, 98.7207209456)  (90, 83.7680718138)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "with open('model.txt', 'w') as outfile:\n",
    "    json.dumps(model_dict, outfile) \n",
    "model_acc = pd.DataFrame(model_dict)\n",
    "model_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_acc['batch_size'] = model_acc.adam.map(lambda x: x[0])\n",
    "model_acc['adam_accuracy'] = model_acc.adam.map(lambda x: x[1])\n",
    "model_acc['sgd_accuracy'] = model_acc.sgd.map(lambda x: x[1])\n",
    "model_acc['adamax_accuracy'] = model_acc.adamax.map(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adam</th>\n",
       "      <th>adamax</th>\n",
       "      <th>sgd</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>adam_accuracy</th>\n",
       "      <th>sgd_accuracy</th>\n",
       "      <th>adamax_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(40, 99.6178762959)</td>\n",
       "      <td>(40, 99.6178763355)</td>\n",
       "      <td>(40, 97.7404873996)</td>\n",
       "      <td>40</td>\n",
       "      <td>99.617876</td>\n",
       "      <td>97.740487</td>\n",
       "      <td>99.617876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(50, 99.285595602)</td>\n",
       "      <td>(50, 99.2689815624)</td>\n",
       "      <td>(50, 86.6755263218)</td>\n",
       "      <td>50</td>\n",
       "      <td>99.285596</td>\n",
       "      <td>86.675526</td>\n",
       "      <td>99.268982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(60, 98.8702461953)</td>\n",
       "      <td>(60, 99.0197727898)</td>\n",
       "      <td>(60, 94.6502788684)</td>\n",
       "      <td>60</td>\n",
       "      <td>98.870246</td>\n",
       "      <td>94.650279</td>\n",
       "      <td>99.019773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(70, 99.7009472329)</td>\n",
       "      <td>(70, 99.48496466)</td>\n",
       "      <td>(70, 93.7863444664)</td>\n",
       "      <td>70</td>\n",
       "      <td>99.700947</td>\n",
       "      <td>93.786344</td>\n",
       "      <td>99.484965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(80, 99.4185075033)</td>\n",
       "      <td>(80, 99.3520512655)</td>\n",
       "      <td>(80, 90.0980251525)</td>\n",
       "      <td>80</td>\n",
       "      <td>99.418508</td>\n",
       "      <td>90.098025</td>\n",
       "      <td>99.352051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(90, 98.9533165203)</td>\n",
       "      <td>(90, 98.7207209456)</td>\n",
       "      <td>(90, 83.7680718138)</td>\n",
       "      <td>90</td>\n",
       "      <td>98.953317</td>\n",
       "      <td>83.768072</td>\n",
       "      <td>98.720721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  adam               adamax                  sgd  batch_size  \\\n",
       "0  (40, 99.6178762959)  (40, 99.6178763355)  (40, 97.7404873996)          40   \n",
       "1   (50, 99.285595602)  (50, 99.2689815624)  (50, 86.6755263218)          50   \n",
       "2  (60, 98.8702461953)  (60, 99.0197727898)  (60, 94.6502788684)          60   \n",
       "3  (70, 99.7009472329)    (70, 99.48496466)  (70, 93.7863444664)          70   \n",
       "4  (80, 99.4185075033)  (80, 99.3520512655)  (80, 90.0980251525)          80   \n",
       "5  (90, 98.9533165203)  (90, 98.7207209456)  (90, 83.7680718138)          90   \n",
       "\n",
       "   adam_accuracy  sgd_accuracy  adamax_accuracy  \n",
       "0      99.617876     97.740487        99.617876  \n",
       "1      99.285596     86.675526        99.268982  \n",
       "2      98.870246     94.650279        99.019773  \n",
       "3      99.700947     93.786344        99.484965  \n",
       "4      99.418508     90.098025        99.352051  \n",
       "5      98.953317     83.768072        98.720721  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGHCAYAAABiT1LUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncZQlI8YYY4xx1P8DUm4hbcsRJr4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b329abba20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(model_acc.batch_size, model_acc.adam_accuracy, '-o', label = 'Adam')\n",
    "plt.plot(model_acc.batch_size, model_acc.sgd_accuracy, '-x', label = 'Sgd')\n",
    "plt.plot(model_acc.batch_size, model_acc.adamax_accuracy, '--r', label = 'adamax')\n",
    "plt.xlabel(\"Batch Size\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"Summary of Accuracy\")\n",
    "plt.legend(loc=3)\n",
    "plt.savefig('accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
